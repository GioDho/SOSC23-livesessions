{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c035b93-4cab-4cb8-8519-ce8bdded0b04",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Project - Day 4 - MLFlow training of your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3220ce18-54f3-4d9c-9ebf-7e4a828049e9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Insert MLFlow parameters\n",
    "The following cell is marked as `parameters`, you might find useful to include MLFlow usable parameters here for varying and experimenting different values for the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e130e26d-a266-43a1-bb1e-53990655e143",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#activation = \n",
    "#reg = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7f8d7e-8c0f-494f-ab86-45526395081a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Excercise\n",
    "\n",
    "Based on the Training step of the project done on day 3:\n",
    "\n",
    "- train a model and store the metrics of the training process in MLFlow. e.g.:\n",
    "```python\n",
    "with mlflow.start_run(tags={\"mlflow.runName\": \"train\"}) as mlrun:\n",
    "\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    !pip install -q tqdm\n",
    "    from tqdm import trange\n",
    "    \n",
    "    n_epochs = 5\n",
    "    n_blocks = y_train.numblocks[0]\n",
    "    \n",
    "    for epoch in trange(n_epochs):\n",
    "        for X, y in zip(X_train.blocks, y_train.blocks):\n",
    "            losses.append(\n",
    "                (len(losses)/n_blocks, classifier.train_on_batch(X.compute(), y.compute()))\n",
    "            )\n",
    "        ls = classifier.test_on_batch(X_valid, y_valid)\n",
    "        val_losses.append(\n",
    "            (len(losses)/n_blocks,ls)\n",
    "            )\n",
    "        mlflow.log_metric(\"loss\", ls, step=int(len(losses)/n_blocks))\n",
    "\n",
    "```\n",
    "\n",
    "- store the model in MLFlow of the usage on the next step of the pipeline, e.g.:\n",
    "\n",
    "```python\n",
    "    classifier.save(\"classifier.keras\")\n",
    "    mlflow.log_artifact(\"classifier.keras\")\n",
    "    prds = classifier.predict(X_valid.compute())\n",
    "    signature = infer_signature(X_valid.compute(), prds)\n",
    "    mlflow.tensorflow.log_model(classifier, \"model\", registered_model_name=\"CYGNO_CNN\", signature=signature)\n",
    "```\n",
    "\n",
    "- store any additional plot that you find useful to track as a MLFlow artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c23e01-9887-43be-8c72-40949ed81920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function definition\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dask, dask.array\n",
    "import tensorflow as tf\n",
    "from tqdm import trange \n",
    "\n",
    "## See Day 2\n",
    "@dask.delayed \n",
    "def load_image(filename: str):\n",
    "    \"\"\"Wrapper function loading image as a dask.delayed\"\"\"\n",
    "    return np.asarray(Image.open(filename))\n",
    "\n",
    "## See Day 2\n",
    "def load_raw_images(filenames):\n",
    "    \"\"\"Load the images from the file paths in `filenames` into a delayed dask-array\"\"\"\n",
    "    return dask.array.stack([\n",
    "        dask.array.from_delayed(load_image(f), shape=(576, 576), dtype=np.uint8) \n",
    "        for f in filenames\n",
    "    ], axis=0)\n",
    "\n",
    "\n",
    "## Discussed in Day 1, implemented in Day 2\n",
    "def windowing(dask_image, x_min, x_max):\n",
    "    \"\"\"Maps the pixel values from the interval [x_min, x_max] to [0, 1]\"\"\"\n",
    "    return dask.array.clip((dask_image - x_min)/(x_max - x_min), 0., 1.)\n",
    "\n",
    "## Discussed in Day 1, implemented in Day 2\n",
    "def crop_center(dask_image, half_win=90):        #64 standard\n",
    "    \"\"\"Crop a numpy-represented image around its center, the resulting image will be a square of side 2*half_win\"\"\"\n",
    "    low, high = 576//2 - half_win, 576//2 + half_win\n",
    "    return dask_image[:,low:high, low:high]\n",
    "\n",
    "import re\n",
    "def energy_keV_from_path(filenames):\n",
    "    \"\"\"\n",
    "    Return a dask array with the energy (in keV) as obtained parsing a sequence of filenames passed \n",
    "    as an argument.\n",
    "    \"\"\"\n",
    "    return dask.array.from_array([float(re.findall(r\"/([0-9]+)_keV\", f)[0]) for f in filenames])\n",
    "\n",
    "def is_nuclear_from_path(filenames):\n",
    "    \"\"\"\n",
    "    Return an array of boolean, true for nuclear recoil, or false for electron recoils as \n",
    "    obtained parsing the list of filenames passed as an argument.\n",
    "    \"\"\"\n",
    "    return dask.array.from_array([float('NR' in re.findall(r\"/([NE]R)/\", f)) for f in filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1920eb-6063-4f89-ba0e-e2190d1e5e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code execution with preproc before ML part\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "input_files = np.array(glob (\"/home/jovyan/data/export/train/*/*/*.png\"))\n",
    "input_files = np.random.permutation(input_files)\n",
    "\n",
    "forvalid=50\n",
    "fortrain_input_files=input_files[forvalid:]\n",
    "forvalid_input_files=input_files[:forvalid]\n",
    "\n",
    "training_set = crop_center(windowing(load_raw_images(fortrain_input_files), 95, 120))\n",
    "validation_set = crop_center(windowing(load_raw_images(forvalid_input_files), 95, 120))\n",
    "\n",
    "training_label = is_nuclear_from_path(fortrain_input_files)\n",
    "validation_label = is_nuclear_from_path(forvalid_input_files)\n",
    "\n",
    "training_energy = energy_keV_from_path(fortrain_input_files)\n",
    "validation_energy = energy_keV_from_path(forvalid_input_files)\n",
    "print(training_set)\n",
    "\n",
    "#Creation CNN\n",
    "## The learning rate defines the leap taken at each update of the weights\n",
    "learning_rate = 1e-3\n",
    "\n",
    "## We create a deep sequential model (layers are executed in a sequence, one after the other)\n",
    "classifier = tf.keras.models.Sequential([\n",
    "    ## We reshape the images making it explicit that they have 1 single channel\n",
    "    tf.keras.layers.Reshape((180, 180, 1), name=\"reshape\"),      #ho fatto la half-win da 90\n",
    "\n",
    "    ## First Convolutional block (conv + conv + max pooling)\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(3,3), activation='relu', kernel_regularizer=tf.keras.regularizers.L2(1e-2), kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(3,3), activation='relu', kernel_regularizer=tf.keras.regularizers.L2(1e-2), kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    ## Second Convolutional block (equal to the previous one)\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(3,3), activation='relu', kernel_regularizer=tf.keras.regularizers.L2(1e-2), kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(3,3), activation='relu', kernel_regularizer=tf.keras.regularizers.L2(1e-2), kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "\n",
    "    ## Finally, we flatten the generated image and we use the computed channels as input of a \n",
    "    ## last dense layer, activated by a sigmoid.\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer='he_normal'),\n",
    "])\n",
    "\n",
    "## Before training we may want to specify the input shape of the dataset:\n",
    "classifier.build(input_shape=(None, 180, 180))\n",
    "\n",
    "classifier.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate)\n",
    ")\n",
    "\n",
    "#Rechunking\n",
    "batch_size = 30\n",
    "\n",
    "X_train = dask.array.rechunk(training_set,(batch_size,180,180))\n",
    "X_valid = dask.array.rechunk(validation_set,(batch_size,180,180))\n",
    "y_train = dask.array.rechunk(training_label,(batch_size,180,180))\n",
    "y_valid = dask.array.rechunk(validation_label,(batch_size,180,180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad127c8-2e82-4d2f-b1af-503d475d6173",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(tags={\"mlflow.runName\": \"train\"}) as mlrun:\n",
    "\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    !pip install -q tqdm\n",
    "    from tqdm import trange\n",
    "    \n",
    "    n_epochs = 5\n",
    "    n_blocks = y_train.numblocks[0]\n",
    "    \n",
    "    for epoch in trange(n_epochs):\n",
    "        for X, y in zip(X_train.blocks, y_train.blocks):\n",
    "            ls=classifier.train_on_batch(X.compute(), y.compute())\n",
    "            losses.append( (len(losses)/n_blocks, ls) )\n",
    "            mlflow.log_metric(\"loss\", ls, step=int(len(losses)/n_blocks))\n",
    "\n",
    "            \n",
    "        val_ls = classifier.test_on_batch(X_valid, y_valid)\n",
    "        val_losses.append(\n",
    "            (len(losses)/n_blocks,val_ls)\n",
    "            )\n",
    "        mlflow.log_metric(\"val_loss\", val_ls, step=int(len(losses)/n_blocks))\n",
    "\n",
    "    predictions = np.concatenate([classifier(tf.constant(X)) for X in list(X_train.blocks) + list(X_valid.blocks)])\n",
    "    labels = dask.array.concatenate([y_train, y_valid]).compute()\n",
    "    plt.hist(predictions[labels>0.5], bins=np.linspace(0, 1, 51), histtype='step', hatch='/'*5, linewidth=2, label=\"Nuclear recoil\")\n",
    "    plt.hist(predictions[labels<0.5], bins=np.linspace(0, 1, 51), histtype='step', hatch='\\\\'*5, linewidth=2, label=\"Electronic recoil\")\n",
    "    plt.legend(title=\"Cygno-SIM\")\n",
    "    plt.xlabel(\"Classifier response\")\n",
    "    plt.ylabel(\"Events\")\n",
    "    plt.yscale('log')\n",
    "    pathfig='outputs/response.png'\n",
    "    plt.savefig(pathfig)\n",
    "\n",
    "    mlflow.log_artifact(pathfig)\n",
    "\n",
    "    classifier.save(\"classifier.keras\")\n",
    "    mlflow.log_artifact(\"classifier.keras\")\n",
    "    prds = classifier.predict(X_valid.compute())\n",
    "    signature = infer_signature(X_valid.compute(), prds)\n",
    "    mlflow.tensorflow.log_model(classifier, \"model\", registered_model_name=\"CYGNO_CNNgiodho\", signature=signature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
